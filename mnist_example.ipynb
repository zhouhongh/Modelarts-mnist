{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# \u57fa\u4e8eCNN\u7684\u624b\u5199\u6570\u5b57\u56fe\u50cf\u8bc6\u522b\u5e94\u7528"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "import moxing.tensorflow as mox\nimport os", "execution_count": 39, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "\u6839\u636e\u6570\u636e\u5b58\u50a8\u548c\u6570\u636e\u8f93\u51fa\u8bbe\u7f6edata_url\u548ctrain_url\u4ee5\u53calog_url\uff08\u4f7f\u7528tf.flags\uff09"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "####### your coding place\uff1a begin  ###########\n# \u6b64\u5904\u5fc5\u987b\u4fee\u6539\u4e3a\u7528\u6237\u6570\u636e\u6876\u4f4d\u7f6e\n\n#\u6570\u636e\u5728OBS\u7684\u5b58\u50a8\u4f4d\u7f6e\u3002\n# eg. s3:// \uff1a\u7edf\u4e00\u8def\u5f84\u8f93\u5165\n#     /uBucket \uff1a\u6876\u540d\uff0c\u7528\u6237\u7684\u79c1\u6709\u6876\u7684\u540d\u79f0 eg. bucket\n#     /notebook/data/\uff1a \u6587\u4ef6\u8def\u5f84\n\ndata_url = 's3://zhh-obs001/test-modelarts/dataset-mnist/' \n\n####### your coding place\uff1a end  ###########", "execution_count": 40, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "train_url = './cache/model/'          #\u8bad\u7ec3\u8f93\u51fa\u4f4d\u7f6e\u3002\nif not mox.file.exists(data_url):\n    raise ValueError('Plese verify your data url!')\nif mox.file.exists(train_url):\n    mox.file.remove(train_url,recursive=True)\nmox.file.make_dirs(train_url)\nlog_url = './cache/log/'            # \u65e5\u5fd7\u5b58\u653e\u4f4d\u7f6e\nif mox.file.exists(log_url):\n    mox.file.remove(log_url,recursive=True)\nmox.file.make_dirs(log_url)", "execution_count": 41, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": " \u901a\u8fc7mox \u80fd\u591f\u5c06\u6570\u636e\u62f7\u8d1d\u5230\u672c\u5730\uff0c\u8fd9\u6837\u80fd\u591f\u52a0\u5feb\u8bad\u7ec3\u3002\u64cd\u4f5c\u5982\u4e0b\uff1a"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# \u672c\u5730\u521b\u5efa\u6570\u636e\u5b58\u50a8\u6587\u4ef6\u5939\nlocal_url = './cache/local_data/'\nif mox.file.exists(local_url):\n    mox.file.remove(local_url,recursive=True)\nos.makedirs(local_url)\n\n#\u5c06\u79c1\u6709\u6876\u4e2d\u7684\u6570\u636e\u62f7\u8d1d\u5230\u672c\u5730mox.file.copy_parallel\uff08\uff09\n\"\"\"\n  Copy all files in src_url to dst_url. Same usage as `shutil.copytree`.\n  Note that this method can only copy a directory. If you want to copy a single file,\n  please use `mox.file.copy`\n\n  Example::\n\n    copy_parallel(src_url='/tmp', dst_url='s3://bucket_name/my_data')\n\n  Assuming files in `/tmp` are:\n\n  * /tmp:\n      * |- train\n          * |- 1.jpg\n          * |- 2.jpg\n      * |- eval\n          * |- 3.jpg\n          * |- 4.jpg\n\n  Then files after copy in `s3://bucket_name/my_data` are:\n\n  * s3://bucket_name/my_data:\n      * |- train\n          * |- 1.jpg\n          * |- 2.jpg\n      * |- eval\n          * |- 3.jpg\n          * |- 4.jpg\n\n  Directory `tmp` will not be copied. If `file_list` is `['train/1.jpg', 'eval/4.jpg']`,\n  then files after copy in `s3://bucket_name/my_data` are:\n\n  * s3://bucket_name/my_data\n      * |- train\n          * |- 1.jpg\n      * |- eval\n          * |- 4.jpg\n\n  :param src_url: Source path or s3 url\n  :param dst_url: Destination path or s3 url\n  :param file_list: A list of relative path to `src_url` of files need to be copied.\n  :param threads: Number of threads or processings in Pool.\n  :param is_processing: If True, multiprocessing is used. If False, multithreading is used.\n  :param use_queue: Whether use queue to manage downloading list.\n  :return: None\n\"\"\"\nmox.file.copy_parallel(data_url, local_url)\ndata_url = local_url\nos.listdir(data_url)", "execution_count": 42, "outputs": [{"output_type": "execute_result", "execution_count": 42, "data": {"text/plain": "['t10k-images-idx3-ubyte',\n 't10k-images-idx3-ubyte.gz',\n 't10k-labels-idx1-ubyte',\n 't10k-labels-idx1-ubyte.gz',\n 'train-labels-idx1-ubyte.gz',\n 'train-images-idx3-ubyte',\n 'train-images-idx3-ubyte.gz',\n 'train-labels-idx1-ubyte']"}, "metadata": {}}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "print(os.getcwd())\nall_files = [f for f in os.listdir(os.getcwd())]#\u8f93\u51fa\u6839path\u4e0b\u7684\u6240\u6709\u6587\u4ef6\u540d\u5230\u4e00\u4e2a\u5217\u8868\u4e2d\n#\u5bf9\u5404\u4e2a\u6587\u4ef6\u8fdb\u884c\u5904\u7406\nprint(all_files)", "execution_count": 43, "outputs": [{"output_type": "stream", "text": "/home/ma-user/work\n['cache']\n", "name": "stdout"}]}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport gzip\nimport os\n\nimport numpy\nfrom scipy import ndimage\n\nfrom six.moves import urllib\n\nimport tensorflow as tf\ntf.reset_default_graph()\n", "execution_count": 44, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "**\u8bf4\u660e 1**  &#160; &#160; \u51fd\u6570 tf.flags.DEFINE_string('data_url', None, 'Dir of dataset')  \u6570\u636e\u8def\u5f84\u3002\n                  \u51fd\u6570tf.flags.DEFINE_string('train_url', None, 'Train Url') \u65e5\u5fd7\u4ee5\u53ca\u751f\u4ea7\u6a21\u578b\u7684\u5b58\u50a8\u8def\u5f84\u3002 \u5f53\u811a\u672c\u8fd0\u884c\u7684\u65f6\u5019\u53ef\u4ee5\u5229\u7528tf.flags\u4f20\u5165\u53c2\u6570\u3002"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "DATA_DIRECTORY = data_url\n# Params for MNIST\nIMAGE_SIZE = 28\nNUM_CHANNELS = 1\nPIXEL_DEPTH = 255\nNUM_LABELS = 10\nVALIDATION_SIZE = 5000  # Size of the validation set.\n\n# filenames = ['train-images-idx3-ubyte.gz','train-labels-idx1-ubyte.gz','t10k-images-idx3-ubyte.gz',\n#              't10k-labels-idx1-ubyte.gz']\n\n# for filename in filenames:\n#   filepath = os.path.join(data_url, filename)\n#   if not mox.file.exists(filepath):\n#     raise ValueError('MNIST dataset file %s not found in %s' % (filepath, local_url))\n\n", "execution_count": 45, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "####  &#160;&#160;\u8bad\u7ec3\u7684main\u51fd\u6570\u5305\u542b\u4e09\u4e2a\u90e8\u5206\uff0c\u8f93\u5165\u5b9a\u4e49\u3001\u6a21\u578b\u5b9a\u4e49\u548c\u8fd0\u884c\u3002\n\n1\uff09 \u8f93\u5165\u51fd\u6570\uff1ainput_fn(run_mode, **kwargs) \u7528\u6237\u53ef\u4ee5\u6839\u636e\u81ea\u5df1\u7684\u8f93\u5165\u7f16\u5199\u3002\u672c\u4f8b\u4e2d\u901a\u8fc7\u8fed\u4ee3\u7684\u65b9\u5f0f\u4ece\u6570\u636e\u96c6\u4e2d\u53d6\u6570\u636e\u3002\n\n\n2\uff09 \u6a21\u578b\u5b9a\u4e49\uff1adef model_fn(inputs, run_mode, **kwargs): \u6a21\u578b\u7ed3\u6784\u5b9a\u4e49\u51fd\u6570\uff0c\u8fd4\u56de mox.ModelSpec(\uff09\uff0c\u7528\u6237\u4f5c\u4e1a\u6a21\u5f0f\u5b9a\u4e49\u8fd4\u56de\u503c\u3002\n\u4f46\u9700\u8981\u6ee1\u8db3\u5982\u4e0b\u6761\u4ef6\uff1a\n\n &#160;&#160; For run_mode == ModeKeys.TRAIN: `loss` is required.\n  \n  &#160;&#160;  For run_mode == ModeKeys.EVAL: `log_info` is required.\n  \n  &#160;&#160;  For run_mode == ModeKeys.PREDICT: `output_info` is required.\n  \n  &#160;&#160;  For run_mode == ModeKeys.EXPORT: `export_spec` is required.\n  \n\n3\uff09 \u6267\u884c\u8bad\u7ec3\uff1a mox.run(\uff09\uff0c\u8bad\u7ec3\u7684\u8fc7\u7a0b\u4e2d\u53ef\u6307\u5b9aoptimizer\u7684\u4e00\u4e9b\u8bbe\u7f6e\uff0c\u8bad\u7ec3batch\u7684\u5927\u5c0f\u7b49\uff0c\u8bbe\u7f6e\u5185\u5bb9\u5982\u4e0b\uff1a\n\n\n &#160;&#160; \u8f93\u5165\u51fd\u6570\uff0c input_fn: An input_fn defined by user. Allows tfrecord or python data. Returns  input tensor list.\n \n &#160;&#160;  \u6a21\u578b\u51fd\u6570\uff0c model_fn: A model_fn defined by user. Returns `mox.ModelSpec`.\n  \n  &#160;&#160; optimizer\u5b9a\u4e49\uff0c optimizer_fn: An optimizer_fn defined by user. Returns an optimizer.\n  \n  &#160;&#160; \u8fd0\u884c\u6a21\u5f0f\u9009\u62e9\uff0c run_mode: Only takes mox.ModeKeys.TRAIN or mox.ModeKeys.EVAL or mox.ModeKeys.PREDICT\n  \n  &#160;&#160; batch\u5927\u5c0f\u8bbe\u7f6e\uff0c batch_size: Mini-batch size.\n  \n &#160;&#160;  \u662f\u5426\u81ea\u52a8\u5316batch\uff0c auto_batch: If True, an extra dimension of batch_size will be expanded to the first\n                     dimension of the return value from `get_split`. Default to True.\n                     \n  &#160;&#160; \u65e5\u5fd7\u4ee5\u53cacheckpoint\u4fdd\u5b58\u4f4d\u7f6e\uff0c log_dir: The directory to save summaries and checkpoints.\n  \n  &#160;&#160; \u6700\u5927\u6570\u91cf\uff0c  max_number_of_steps: Maximum steps for each worker.\n                          \n  &#160;&#160; \u65e5\u5fd7\u6253\u5370\uff0c log_every_n_steps: Step period to print logs to std I/O.\n     \n  &#160;&#160; \u662f\u5426\u8f93\u51fa\u6a21\u578b\uff0c export_model: True or False. Where to export model after running the job.\n\n"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "def maybe_download(filename):\n    \"\"\"Download the data from Yann's website, unless it's already here.\"\"\"\n    if not tf.gfile.Exists(DATA_DIRECTORY):\n        tf.gfile.MakeDirs(DATA_DIRECTORY)\n    filepath = os.path.join(DATA_DIRECTORY, filename)\n    if not tf.gfile.Exists(filepath):\n        print(filepath,\" does not exist\")\n        filepath, _ = urllib.request.urlretrieve(SOURCE_URL + filename, filepath)\n        with tf.gfile.GFile(filepath) as f:\n            size = f.size()\n        print('Successfully downloaded', filename, size, 'bytes.')\n    return filepath\n\n# Extract the images\ndef extract_data(filename, num_images):\n    \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n\n    Values are rescaled from [0, 255] down to [-0.5, 0.5].\n    \"\"\"\n    print('Extracting', filename)\n    with gzip.open(filename) as bytestream:\n        bytestream.read(16)\n        buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images * NUM_CHANNELS)\n        data = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.float32)\n        data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n        data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)\n        data = numpy.reshape(data, [num_images, -1])\n    return data\n\n# Extract the labels\ndef extract_labels(filename, num_images):\n    \"\"\"Extract the labels into a vector of int64 label IDs.\"\"\"\n    print('Extracting', filename)\n    with gzip.open(filename) as bytestream:\n        bytestream.read(8)\n        buf = bytestream.read(1 * num_images)\n        labels = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.int64)\n        num_labels_data = len(labels)\n        one_hot_encoding = numpy.zeros((num_labels_data,NUM_LABELS))\n        one_hot_encoding[numpy.arange(num_labels_data),labels] = 1\n        one_hot_encoding = numpy.reshape(one_hot_encoding, [-1, NUM_LABELS])\n    return one_hot_encoding\n\n# Augment training data\ndef expend_training_data(images, labels):\n\n    expanded_images = []\n    expanded_labels = []\n\n    j = 0 # counter\n    for x, y in zip(images, labels):\n        j = j+1\n        if j%100==0:\n            print ('expanding data : %03d / %03d' % (j,numpy.size(images,0)))\n\n        # register original data\n        expanded_images.append(x)\n        expanded_labels.append(y)\n\n        # get a value for the background\n        # zero is the expected value, but median() is used to estimate background's value \n        bg_value = numpy.median(x) # this is regarded as background's value        \n        image = numpy.reshape(x, (-1, 28))\n\n        for i in range(4):\n            # rotate the image with random degree\n            angle = numpy.random.randint(-15,15,1)\n            new_img = ndimage.rotate(image,angle,reshape=False, cval=bg_value)\n\n            # shift the image with random distance\n            shift = numpy.random.randint(-2, 2, 2)\n            new_img_ = ndimage.shift(new_img,shift, cval=bg_value)\n\n            # register new training data\n            expanded_images.append(numpy.reshape(new_img_, 784))\n            expanded_labels.append(y)\n\n    # images and labels are concatenated for random-shuffle at each epoch\n    # notice that pair of image and label should not be broken\n    expanded_train_total_data = numpy.concatenate((expanded_images, expanded_labels), axis=1)\n    numpy.random.shuffle(expanded_train_total_data)\n\n    return expanded_train_total_data\n\n# Prepare MNISt data\ndef prepare_MNIST_data(use_data_augmentation=True):\n    # Get the data.\n    train_data_filename = maybe_download('train-images-idx3-ubyte.gz')\n    train_labels_filename = maybe_download('train-labels-idx1-ubyte.gz')\n    test_data_filename = maybe_download('t10k-images-idx3-ubyte.gz')\n    test_labels_filename = maybe_download('t10k-labels-idx1-ubyte.gz')\n\n    # Extract it into numpy arrays.\n    train_data = extract_data(train_data_filename, 60000)\n    train_labels = extract_labels(train_labels_filename, 60000)\n    test_data = extract_data(test_data_filename, 10000)\n    test_labels = extract_labels(test_labels_filename, 10000)\n\n    # Generate a validation set.\n    validation_data = train_data[:VALIDATION_SIZE, :]\n    validation_labels = train_labels[:VALIDATION_SIZE,:]\n    train_data = train_data[VALIDATION_SIZE:, :]\n    train_labels = train_labels[VALIDATION_SIZE:,:]\n\n    # Concatenate train_data & train_labels for random shuffle\n    if use_data_augmentation:\n        train_total_data = expend_training_data(train_data, train_labels)\n    else:\n        train_total_data = numpy.concatenate((train_data, train_labels), axis=1)\n\n    train_size = train_total_data.shape[0]\n\n    return train_total_data, train_size, validation_data, validation_labels, test_data, test_labels\n", "execution_count": 46, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "MODEL_DIRECTORY = train_url\nLOGS_DIRECTORY = log_url\n# Params for Train\ntraining_epochs = 10# 10 for augmented training data, 20 for training data\nTRAIN_BATCH_SIZE = 50\ndisplay_step = 100\nvalidation_step = 500\n\n# Params for test\nTEST_BATCH_SIZE = 5000\nimport tensorflow.contrib.slim as slim", "execution_count": 47, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# Create model of CNN with slim api\ndef CNN(inputs, is_training=True):\n    batch_norm_params = {'is_training': is_training, 'decay': 0.9, 'updates_collections': None}\n    with slim.arg_scope([slim.conv2d, slim.fully_connected],\n                        normalizer_fn=slim.batch_norm,\n                        normalizer_params=batch_norm_params):\n        x = tf.reshape(inputs, [-1, 28, 28, 1])\n\n        # For slim.conv2d, default argument values are like\n        # normalizer_fn = None, normalizer_params = None, <== slim.arg_scope changes these arguments\n        # padding='SAME', activation_fn=nn.relu,\n        # weights_initializer = initializers.xavier_initializer(),\n        # biases_initializer = init_ops.zeros_initializer,\n        net = slim.conv2d(x, 32, [5, 5], scope='conv1')\n        net = slim.max_pool2d(net, [2, 2], scope='pool1')\n        net = slim.conv2d(net, 64, [5, 5], scope='conv2')\n        net = slim.max_pool2d(net, [2, 2], scope='pool2')\n        net = slim.flatten(net, scope='flatten3')\n\n        # For slim.fully_connected, default argument values are like\n        # activation_fn = nn.relu,\n        # normalizer_fn = None, normalizer_params = None, <== slim.arg_scope changes these arguments\n        # weights_initializer = initializers.xavier_initializer(),\n        # biases_initializer = init_ops.zeros_initializer,\n        net = slim.fully_connected(net, 1024, scope='fc3')\n        net = slim.dropout(net, is_training=is_training, scope='dropout3')  # 0.5 by default\n        outputs = slim.fully_connected(net, 10, activation_fn=None, normalizer_fn=None, scope='fco')\n    return outputs", "execution_count": 48, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "\u4e0b\u9762\u662f\u8bad\u7ec3\u51fd\u6570 def train()"}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "def train():\n\n    # Some parameters\n    batch_size = TRAIN_BATCH_SIZE\n    num_labels = NUM_LABELS\n\n    # Prepare mnist data\n    train_total_data, train_size, validation_data, validation_labels, test_data, test_labels = prepare_MNIST_data(True)\n\n    # Boolean for MODE of train or test\n    is_training = tf.placeholder(tf.bool, name='MODE')\n\n    # tf Graph input\n    x = tf.placeholder(tf.float32, [None, 784])\n    y_ = tf.placeholder(tf.float32, [None, 10]) #answer\n\n    # Predict\n    y = CNN(x)\n\n    # Get loss of model\n    with tf.name_scope(\"LOSS\"):\n        loss = slim.losses.softmax_cross_entropy(y,y_)\n\n    # Create a summary to monitor loss tensor\n    tf.summary.scalar('loss', loss)\n\n    # Define optimizer\n    with tf.name_scope(\"ADAM\"):\n        # Optimizer: set up a variable that's incremented once per batch and\n        # controls the learning rate decay.\n        batch = tf.Variable(0)\n\n        learning_rate = tf.train.exponential_decay(\n            1e-4,  # Base learning rate.\n            batch * batch_size,  # Current index into the dataset.\n            train_size,  # Decay step.\n            0.95,  # Decay rate.\n            staircase=True)\n        # Use simple momentum for the optimization.\n        train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss,global_step=batch)\n\n    # Create a summary to monitor learning_rate tensor\n    tf.summary.scalar('learning_rate', learning_rate)\n\n    # Get accuracy of model\n    with tf.name_scope(\"ACC\"):\n        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\n    # Create a summary to monitor accuracy tensor\n    tf.summary.scalar('acc', accuracy)\n\n    # Merge all summaries into a single op\n    merged_summary_op = tf.summary.merge_all()\n\n    # Add ops to save and restore all the variables\n    saver = tf.train.Saver()\n    sess = tf.InteractiveSession()\n    sess.run(tf.global_variables_initializer(), feed_dict={is_training: True})\n\n    # Training cycle\n    total_batch = int(train_size / batch_size)\n\n    # op to write logs to Tensorboard\n    summary_writer = tf.summary.FileWriter(LOGS_DIRECTORY, graph=tf.get_default_graph())\n\n    # Save the maximum accuracy value for validation data\n    max_acc = 0.\n\n    # Loop for epoch\n    for epoch in range(training_epochs):\n\n        # Random shuffling\n        numpy.random.shuffle(train_total_data)\n        train_data_ = train_total_data[:, :-num_labels]\n        train_labels_ = train_total_data[:, -num_labels:]\n\n        # Loop over all batches\n        for i in range(total_batch):\n\n            # Compute the offset of the current minibatch in the data.\n            offset = (i * batch_size) % (train_size)\n            batch_xs = train_data_[offset:(offset + batch_size), :]\n            batch_ys = train_labels_[offset:(offset + batch_size), :]\n\n            # Run optimization op (backprop), loss op (to get loss value)\n            # and summary nodes\n            _, train_accuracy, summary = sess.run([train_step, accuracy, merged_summary_op] , feed_dict={x: batch_xs, y_: batch_ys, is_training: True})\n\n            # Write logs at every iteration\n            summary_writer.add_summary(summary, epoch * total_batch + i)\n\n            # Display logs\n            if i % display_step == 0:\n                print(\"Epoch:\", '%04d,' % (epoch + 1),\n                \"batch_index %4d/%4d, training accuracy %.5f\" % (i, total_batch, train_accuracy))\n\n            # Get accuracy for validation data\n            if i % validation_step == 0:\n                # Calculate accuracy\n                validation_accuracy = sess.run(accuracy,\n                feed_dict={x: validation_data, y_: validation_labels, is_training: False})\n\n                print(\"Epoch:\", '%04d,' % (epoch + 1),\n                \"batch_index %4d/%4d, validation accuracy %.5f\" % (i, total_batch, validation_accuracy))\n\n            # Save the current model if the maximum accuracy is updated\n            if validation_accuracy > max_acc:\n                max_acc = validation_accuracy\n                save_path = saver.save(sess, MODEL_DIRECTORY)\n                print(\"Model updated and saved in file: %s\" % save_path)\n\n    print(\"Optimization Finished!\")\n\n    # Restore variables from disk\n    saver.restore(sess, MODEL_DIRECTORY)\n\n    # Calculate accuracy for all mnist test images\n    test_size = test_labels.shape[0]\n    batch_size = TEST_BATCH_SIZE\n    total_batch = int(test_size / batch_size)\n\n    acc_buffer = []\n\n    # Loop over all batches\n    for i in range(total_batch):\n        # Compute the offset of the current minibatch in the data.\n        offset = (i * batch_size) % (test_size)\n        batch_xs = test_data[offset:(offset + batch_size), :]\n        batch_ys = test_labels[offset:(offset + batch_size), :]\n\n        y_final = sess.run(y, feed_dict={x: batch_xs, y_: batch_ys, is_training: False})\n        correct_prediction = numpy.equal(numpy.argmax(y_final, 1), numpy.argmax(batch_ys, 1))\n        acc_buffer.append(numpy.sum(correct_prediction) / batch_size)\n\n    print(\"test accuracy for the stored model: %g\" % numpy.mean(acc_buffer))\n", "execution_count": 49, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "train()", "execution_count": 50, "outputs": [{"output_type": "stream", "text": "Extracting ./cache/local_data/train-images-idx3-ubyte.gz\nExtracting ./cache/local_data/train-labels-idx1-ubyte.gz\nExtracting ./cache/local_data/t10k-images-idx3-ubyte.gz\nExtracting ./cache/local_data/t10k-labels-idx1-ubyte.gz\nexpanding data : 100 / 55000\nexpanding data : 200 / 55000\nexpanding data : 300 / 55000\nexpanding data : 400 / 55000\nexpanding data : 500 / 55000\nexpanding data : 600 / 55000\nexpanding data : 700 / 55000\nexpanding data : 800 / 55000\nexpanding data : 900 / 55000\nexpanding data : 1000 / 55000\nexpanding data : 1100 / 55000\nexpanding data : 1200 / 55000\nexpanding data : 1300 / 55000\nexpanding data : 1400 / 55000\nexpanding data : 1500 / 55000\nexpanding data : 1600 / 55000\nexpanding data : 1700 / 55000\nexpanding data : 1800 / 55000\nexpanding data : 1900 / 55000\nexpanding data : 2000 / 55000\nexpanding data : 2100 / 55000\nexpanding data : 2200 / 55000\nexpanding data : 2300 / 55000\nexpanding data : 2400 / 55000\nexpanding data : 2500 / 55000\nexpanding data : 2600 / 55000\nexpanding data : 2700 / 55000\nexpanding data : 2800 / 55000\nexpanding data : 2900 / 55000\nexpanding data : 3000 / 55000\nexpanding data : 3100 / 55000\nexpanding data : 3200 / 55000\nexpanding data : 3300 / 55000\nexpanding data : 3400 / 55000\nexpanding data : 3500 / 55000\nexpanding data : 3600 / 55000\nexpanding data : 3700 / 55000\nexpanding data : 3800 / 55000\nexpanding data : 3900 / 55000\nexpanding data : 4000 / 55000\nexpanding data : 4100 / 55000\nexpanding data : 4200 / 55000\nexpanding data : 4300 / 55000\nexpanding data : 4400 / 55000\nexpanding data : 4500 / 55000\nexpanding data : 4600 / 55000\nexpanding data : 4700 / 55000\nexpanding data : 4800 / 55000\nexpanding data : 4900 / 55000\nexpanding data : 5000 / 55000\nexpanding data : 5100 / 55000\nexpanding data : 5200 / 55000\nexpanding data : 5300 / 55000\nexpanding data : 5400 / 55000\nexpanding data : 5500 / 55000\nexpanding data : 5600 / 55000\nexpanding data : 5700 / 55000\nexpanding data : 5800 / 55000\nexpanding data : 5900 / 55000\nexpanding data : 6000 / 55000\nexpanding data : 6100 / 55000\nexpanding data : 6200 / 55000\nexpanding data : 6300 / 55000\nexpanding data : 6400 / 55000\nexpanding data : 6500 / 55000\nexpanding data : 6600 / 55000\nexpanding data : 6700 / 55000\nexpanding data : 6800 / 55000\nexpanding data : 6900 / 55000\nexpanding data : 7000 / 55000\nexpanding data : 7100 / 55000\nexpanding data : 7200 / 55000\nexpanding data : 7300 / 55000\nexpanding data : 7400 / 55000\nexpanding data : 7500 / 55000\nexpanding data : 7600 / 55000\nexpanding data : 7700 / 55000\nexpanding data : 7800 / 55000\nexpanding data : 7900 / 55000\nexpanding data : 8000 / 55000\nexpanding data : 8100 / 55000\nexpanding data : 8200 / 55000\nexpanding data : 8300 / 55000\nexpanding data : 8400 / 55000\nexpanding data : 8500 / 55000\nexpanding data : 8600 / 55000\nexpanding data : 8700 / 55000\nexpanding data : 8800 / 55000\nexpanding data : 8900 / 55000\nexpanding data : 9000 / 55000\nexpanding data : 9100 / 55000\nexpanding data : 9200 / 55000\nexpanding data : 9300 / 55000\nexpanding data : 9400 / 55000\nexpanding data : 9500 / 55000\nexpanding data : 9600 / 55000\nexpanding data : 9700 / 55000\nexpanding data : 9800 / 55000\nexpanding data : 9900 / 55000\nexpanding data : 10000 / 55000\nexpanding data : 10100 / 55000\nexpanding data : 10200 / 55000\nexpanding data : 10300 / 55000\nexpanding data : 10400 / 55000\nexpanding data : 10500 / 55000\nexpanding data : 10600 / 55000\nexpanding data : 10700 / 55000\nexpanding data : 10800 / 55000\nexpanding data : 10900 / 55000\nexpanding data : 11000 / 55000\nexpanding data : 11100 / 55000\nexpanding data : 11200 / 55000\nexpanding data : 11300 / 55000\nexpanding data : 11400 / 55000\nexpanding data : 11500 / 55000\nexpanding data : 11600 / 55000\nexpanding data : 11700 / 55000\nexpanding data : 11800 / 55000\nexpanding data : 11900 / 55000\nexpanding data : 12000 / 55000\nexpanding data : 12100 / 55000\nexpanding data : 12200 / 55000\nexpanding data : 12300 / 55000\nexpanding data : 12400 / 55000\nexpanding data : 12500 / 55000\nexpanding data : 12600 / 55000\nexpanding data : 12700 / 55000\nexpanding data : 12800 / 55000\nexpanding data : 12900 / 55000\nexpanding data : 13000 / 55000\nexpanding data : 13100 / 55000\nexpanding data : 13200 / 55000\nexpanding data : 13300 / 55000\nexpanding data : 13400 / 55000\nexpanding data : 13500 / 55000\nexpanding data : 13600 / 55000\nexpanding data : 13700 / 55000\nexpanding data : 13800 / 55000\nexpanding data : 13900 / 55000\nexpanding data : 14000 / 55000\nexpanding data : 14100 / 55000\nexpanding data : 14200 / 55000\nexpanding data : 14300 / 55000\nexpanding data : 14400 / 55000\nexpanding data : 14500 / 55000\nexpanding data : 14600 / 55000\nexpanding data : 14700 / 55000\nexpanding data : 14800 / 55000\nexpanding data : 14900 / 55000\nexpanding data : 15000 / 55000\nexpanding data : 15100 / 55000\nexpanding data : 15200 / 55000\nexpanding data : 15300 / 55000\nexpanding data : 15400 / 55000\nexpanding data : 15500 / 55000\nexpanding data : 15600 / 55000\nexpanding data : 15700 / 55000\nexpanding data : 15800 / 55000\nexpanding data : 15900 / 55000\nexpanding data : 16000 / 55000\nexpanding data : 16100 / 55000\nexpanding data : 16200 / 55000\nexpanding data : 16300 / 55000\nexpanding data : 16400 / 55000\nexpanding data : 16500 / 55000\nexpanding data : 16600 / 55000\nexpanding data : 16700 / 55000\nexpanding data : 16800 / 55000\nexpanding data : 16900 / 55000\nexpanding data : 17000 / 55000\nexpanding data : 17100 / 55000\nexpanding data : 17200 / 55000\nexpanding data : 17300 / 55000\nexpanding data : 17400 / 55000\nexpanding data : 17500 / 55000\nexpanding data : 17600 / 55000\nexpanding data : 17700 / 55000\nexpanding data : 17800 / 55000\nexpanding data : 17900 / 55000\nexpanding data : 18000 / 55000\nexpanding data : 18100 / 55000\nexpanding data : 18200 / 55000\nexpanding data : 18300 / 55000\nexpanding data : 18400 / 55000\nexpanding data : 18500 / 55000\nexpanding data : 18600 / 55000\nexpanding data : 18700 / 55000\nexpanding data : 18800 / 55000\nexpanding data : 18900 / 55000\nexpanding data : 19000 / 55000\nexpanding data : 19100 / 55000\nexpanding data : 19200 / 55000\nexpanding data : 19300 / 55000\nexpanding data : 19400 / 55000\nexpanding data : 19500 / 55000\nexpanding data : 19600 / 55000\nexpanding data : 19700 / 55000\nexpanding data : 19800 / 55000\nexpanding data : 19900 / 55000\nexpanding data : 20000 / 55000\nexpanding data : 20100 / 55000\nexpanding data : 20200 / 55000\nexpanding data : 20300 / 55000\nexpanding data : 20400 / 55000\nexpanding data : 20500 / 55000\nexpanding data : 20600 / 55000\nexpanding data : 20700 / 55000\nexpanding data : 20800 / 55000\nexpanding data : 20900 / 55000\nexpanding data : 21000 / 55000\nexpanding data : 21100 / 55000\nexpanding data : 21200 / 55000\nexpanding data : 21300 / 55000\nexpanding data : 21400 / 55000\nexpanding data : 21500 / 55000\nexpanding data : 21600 / 55000\nexpanding data : 21700 / 55000\nexpanding data : 21800 / 55000\nexpanding data : 21900 / 55000\nexpanding data : 22000 / 55000\nexpanding data : 22100 / 55000\nexpanding data : 22200 / 55000\nexpanding data : 22300 / 55000\nexpanding data : 22400 / 55000\nexpanding data : 22500 / 55000\nexpanding data : 22600 / 55000\nexpanding data : 22700 / 55000\nexpanding data : 22800 / 55000\nexpanding data : 22900 / 55000\nexpanding data : 23000 / 55000\nexpanding data : 23100 / 55000\nexpanding data : 23200 / 55000\nexpanding data : 23300 / 55000\nexpanding data : 23400 / 55000\nexpanding data : 23500 / 55000\nexpanding data : 23600 / 55000\nexpanding data : 23700 / 55000\nexpanding data : 23800 / 55000\nexpanding data : 23900 / 55000\nexpanding data : 24000 / 55000\nexpanding data : 24100 / 55000\nexpanding data : 24200 / 55000\nexpanding data : 24300 / 55000\nexpanding data : 24400 / 55000\nexpanding data : 24500 / 55000\nexpanding data : 24600 / 55000\nexpanding data : 24700 / 55000\nexpanding data : 24800 / 55000\nexpanding data : 24900 / 55000\nexpanding data : 25000 / 55000\nexpanding data : 25100 / 55000\nexpanding data : 25200 / 55000\nexpanding data : 25300 / 55000\nexpanding data : 25400 / 55000\nexpanding data : 25500 / 55000\nexpanding data : 25600 / 55000\nexpanding data : 25700 / 55000\nexpanding data : 25800 / 55000\nexpanding data : 25900 / 55000\nexpanding data : 26000 / 55000\nexpanding data : 26100 / 55000\n", "name": "stdout"}, {"output_type": "stream", "text": "expanding data : 26200 / 55000\nexpanding data : 26300 / 55000\nexpanding data : 26400 / 55000\nexpanding data : 26500 / 55000\nexpanding data : 26600 / 55000\nexpanding data : 26700 / 55000\nexpanding data : 26800 / 55000\nexpanding data : 26900 / 55000\nexpanding data : 27000 / 55000\nexpanding data : 27100 / 55000\nexpanding data : 27200 / 55000\nexpanding data : 27300 / 55000\nexpanding data : 27400 / 55000\nexpanding data : 27500 / 55000\nexpanding data : 27600 / 55000\nexpanding data : 27700 / 55000\nexpanding data : 27800 / 55000\nexpanding data : 27900 / 55000\nexpanding data : 28000 / 55000\nexpanding data : 28100 / 55000\nexpanding data : 28200 / 55000\nexpanding data : 28300 / 55000\nexpanding data : 28400 / 55000\nexpanding data : 28500 / 55000\nexpanding data : 28600 / 55000\nexpanding data : 28700 / 55000\nexpanding data : 28800 / 55000\nexpanding data : 28900 / 55000\nexpanding data : 29000 / 55000\nexpanding data : 29100 / 55000\nexpanding data : 29200 / 55000\nexpanding data : 29300 / 55000\nexpanding data : 29400 / 55000\nexpanding data : 29500 / 55000\nexpanding data : 29600 / 55000\nexpanding data : 29700 / 55000\nexpanding data : 29800 / 55000\nexpanding data : 29900 / 55000\nexpanding data : 30000 / 55000\nexpanding data : 30100 / 55000\nexpanding data : 30200 / 55000\nexpanding data : 30300 / 55000\nexpanding data : 30400 / 55000\nexpanding data : 30500 / 55000\nexpanding data : 30600 / 55000\nexpanding data : 30700 / 55000\nexpanding data : 30800 / 55000\nexpanding data : 30900 / 55000\nexpanding data : 31000 / 55000\nexpanding data : 31100 / 55000\nexpanding data : 31200 / 55000\nexpanding data : 31300 / 55000\nexpanding data : 31400 / 55000\nexpanding data : 31500 / 55000\nexpanding data : 31600 / 55000\nexpanding data : 31700 / 55000\nexpanding data : 31800 / 55000\nexpanding data : 31900 / 55000\nexpanding data : 32000 / 55000\nexpanding data : 32100 / 55000\nexpanding data : 32200 / 55000\nexpanding data : 32300 / 55000\nexpanding data : 32400 / 55000\nexpanding data : 32500 / 55000\nexpanding data : 32600 / 55000\nexpanding data : 32700 / 55000\nexpanding data : 32800 / 55000\nexpanding data : 32900 / 55000\nexpanding data : 33000 / 55000\nexpanding data : 33100 / 55000\nexpanding data : 33200 / 55000\nexpanding data : 33300 / 55000\nexpanding data : 33400 / 55000\nexpanding data : 33500 / 55000\nexpanding data : 33600 / 55000\nexpanding data : 33700 / 55000\nexpanding data : 33800 / 55000\nexpanding data : 33900 / 55000\nexpanding data : 34000 / 55000\nexpanding data : 34100 / 55000\nexpanding data : 34200 / 55000\nexpanding data : 34300 / 55000\nexpanding data : 34400 / 55000\nexpanding data : 34500 / 55000\nexpanding data : 34600 / 55000\nexpanding data : 34700 / 55000\nexpanding data : 34800 / 55000\nexpanding data : 34900 / 55000\nexpanding data : 35000 / 55000\nexpanding data : 35100 / 55000\nexpanding data : 35200 / 55000\nexpanding data : 35300 / 55000\nexpanding data : 35400 / 55000\nexpanding data : 35500 / 55000\nexpanding data : 35600 / 55000\nexpanding data : 35700 / 55000\nexpanding data : 35800 / 55000\nexpanding data : 35900 / 55000\nexpanding data : 36000 / 55000\nexpanding data : 36100 / 55000\nexpanding data : 36200 / 55000\nexpanding data : 36300 / 55000\nexpanding data : 36400 / 55000\nexpanding data : 36500 / 55000\nexpanding data : 36600 / 55000\nexpanding data : 36700 / 55000\nexpanding data : 36800 / 55000\nexpanding data : 36900 / 55000\nexpanding data : 37000 / 55000\nexpanding data : 37100 / 55000\nexpanding data : 37200 / 55000\nexpanding data : 37300 / 55000\nexpanding data : 37400 / 55000\nexpanding data : 37500 / 55000\nexpanding data : 37600 / 55000\nexpanding data : 37700 / 55000\nexpanding data : 37800 / 55000\nexpanding data : 37900 / 55000\nexpanding data : 38000 / 55000\nexpanding data : 38100 / 55000\nexpanding data : 38200 / 55000\nexpanding data : 38300 / 55000\nexpanding data : 38400 / 55000\nexpanding data : 38500 / 55000\nexpanding data : 38600 / 55000\nexpanding data : 38700 / 55000\nexpanding data : 38800 / 55000\nexpanding data : 38900 / 55000\nexpanding data : 39000 / 55000\nexpanding data : 39100 / 55000\nexpanding data : 39200 / 55000\nexpanding data : 39300 / 55000\nexpanding data : 39400 / 55000\nexpanding data : 39500 / 55000\nexpanding data : 39600 / 55000\nexpanding data : 39700 / 55000\nexpanding data : 39800 / 55000\nexpanding data : 39900 / 55000\nexpanding data : 40000 / 55000\nexpanding data : 40100 / 55000\nexpanding data : 40200 / 55000\nexpanding data : 40300 / 55000\nexpanding data : 40400 / 55000\nexpanding data : 40500 / 55000\nexpanding data : 40600 / 55000\nexpanding data : 40700 / 55000\nexpanding data : 40800 / 55000\nexpanding data : 40900 / 55000\nexpanding data : 41000 / 55000\nexpanding data : 41100 / 55000\nexpanding data : 41200 / 55000\nexpanding data : 41300 / 55000\nexpanding data : 41400 / 55000\nexpanding data : 41500 / 55000\nexpanding data : 41600 / 55000\nexpanding data : 41700 / 55000\nexpanding data : 41800 / 55000\nexpanding data : 41900 / 55000\nexpanding data : 42000 / 55000\nexpanding data : 42100 / 55000\nexpanding data : 42200 / 55000\nexpanding data : 42300 / 55000\nexpanding data : 42400 / 55000\nexpanding data : 42500 / 55000\nexpanding data : 42600 / 55000\nexpanding data : 42700 / 55000\nexpanding data : 42800 / 55000\nexpanding data : 42900 / 55000\nexpanding data : 43000 / 55000\nexpanding data : 43100 / 55000\nexpanding data : 43200 / 55000\nexpanding data : 43300 / 55000\nexpanding data : 43400 / 55000\nexpanding data : 43500 / 55000\nexpanding data : 43600 / 55000\nexpanding data : 43700 / 55000\nexpanding data : 43800 / 55000\nexpanding data : 43900 / 55000\nexpanding data : 44000 / 55000\nexpanding data : 44100 / 55000\nexpanding data : 44200 / 55000\nexpanding data : 44300 / 55000\nexpanding data : 44400 / 55000\nexpanding data : 44500 / 55000\nexpanding data : 44600 / 55000\nexpanding data : 44700 / 55000\nexpanding data : 44800 / 55000\nexpanding data : 44900 / 55000\nexpanding data : 45000 / 55000\nexpanding data : 45100 / 55000\nexpanding data : 45200 / 55000\nexpanding data : 45300 / 55000\nexpanding data : 45400 / 55000\nexpanding data : 45500 / 55000\nexpanding data : 45600 / 55000\nexpanding data : 45700 / 55000\nexpanding data : 45800 / 55000\nexpanding data : 45900 / 55000\nexpanding data : 46000 / 55000\nexpanding data : 46100 / 55000\nexpanding data : 46200 / 55000\nexpanding data : 46300 / 55000\nexpanding data : 46400 / 55000\nexpanding data : 46500 / 55000\nexpanding data : 46600 / 55000\nexpanding data : 46700 / 55000\nexpanding data : 46800 / 55000\nexpanding data : 46900 / 55000\nexpanding data : 47000 / 55000\nexpanding data : 47100 / 55000\nexpanding data : 47200 / 55000\nexpanding data : 47300 / 55000\nexpanding data : 47400 / 55000\nexpanding data : 47500 / 55000\nexpanding data : 47600 / 55000\nexpanding data : 47700 / 55000\nexpanding data : 47800 / 55000\nexpanding data : 47900 / 55000\nexpanding data : 48000 / 55000\nexpanding data : 48100 / 55000\nexpanding data : 48200 / 55000\nexpanding data : 48300 / 55000\nexpanding data : 48400 / 55000\nexpanding data : 48500 / 55000\nexpanding data : 48600 / 55000\nexpanding data : 48700 / 55000\nexpanding data : 48800 / 55000\nexpanding data : 48900 / 55000\nexpanding data : 49000 / 55000\nexpanding data : 49100 / 55000\nexpanding data : 49200 / 55000\nexpanding data : 49300 / 55000\nexpanding data : 49400 / 55000\nexpanding data : 49500 / 55000\nexpanding data : 49600 / 55000\nexpanding data : 49700 / 55000\nexpanding data : 49800 / 55000\nexpanding data : 49900 / 55000\nexpanding data : 50000 / 55000\nexpanding data : 50100 / 55000\nexpanding data : 50200 / 55000\nexpanding data : 50300 / 55000\nexpanding data : 50400 / 55000\nexpanding data : 50500 / 55000\nexpanding data : 50600 / 55000\nexpanding data : 50700 / 55000\nexpanding data : 50800 / 55000\nexpanding data : 50900 / 55000\nexpanding data : 51000 / 55000\nexpanding data : 51100 / 55000\nexpanding data : 51200 / 55000\nexpanding data : 51300 / 55000\nexpanding data : 51400 / 55000\nexpanding data : 51500 / 55000\nexpanding data : 51600 / 55000\nexpanding data : 51700 / 55000\nexpanding data : 51800 / 55000\nexpanding data : 51900 / 55000\nexpanding data : 52000 / 55000\nexpanding data : 52100 / 55000\nexpanding data : 52200 / 55000\nexpanding data : 52300 / 55000\nexpanding data : 52400 / 55000\nexpanding data : 52500 / 55000\nexpanding data : 52600 / 55000\nexpanding data : 52700 / 55000\n", "name": "stdout"}, {"output_type": "stream", "text": "expanding data : 52800 / 55000\nexpanding data : 52900 / 55000\nexpanding data : 53000 / 55000\nexpanding data : 53100 / 55000\nexpanding data : 53200 / 55000\nexpanding data : 53300 / 55000\nexpanding data : 53400 / 55000\nexpanding data : 53500 / 55000\nexpanding data : 53600 / 55000\nexpanding data : 53700 / 55000\nexpanding data : 53800 / 55000\nexpanding data : 53900 / 55000\nexpanding data : 54000 / 55000\nexpanding data : 54100 / 55000\nexpanding data : 54200 / 55000\nexpanding data : 54300 / 55000\nexpanding data : 54400 / 55000\nexpanding data : 54500 / 55000\nexpanding data : 54600 / 55000\nexpanding data : 54700 / 55000\nexpanding data : 54800 / 55000\nexpanding data : 54900 / 55000\nexpanding data : 55000 / 55000\n", "name": "stdout"}, {"output_type": "stream", "text": "/home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages/tensorflow/python/client/session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n  warnings.warn('An interactive session is already active. This can '\n", "name": "stderr"}, {"output_type": "stream", "text": "Epoch: 0001, batch_index    0/5500, training accuracy 0.20000\nEpoch: 0001, batch_index    0/5500, validation accuracy 0.13360\nModel updated and saved in file: ./cache/model/\nEpoch: 0001, batch_index  100/5500, training accuracy 0.90000\nEpoch: 0001, batch_index  200/5500, training accuracy 0.94000\nEpoch: 0001, batch_index  300/5500, training accuracy 0.98000\nEpoch: 0001, batch_index  400/5500, training accuracy 0.86000\nEpoch: 0001, batch_index  500/5500, training accuracy 0.94000\nEpoch: 0001, batch_index  500/5500, validation accuracy 0.97120\nModel updated and saved in file: ./cache/model/\nEpoch: 0001, batch_index  600/5500, training accuracy 0.98000\nEpoch: 0001, batch_index  700/5500, training accuracy 0.98000\nEpoch: 0001, batch_index  800/5500, training accuracy 1.00000\nEpoch: 0001, batch_index  900/5500, training accuracy 0.98000\nEpoch: 0001, batch_index 1000/5500, training accuracy 0.96000\nEpoch: 0001, batch_index 1000/5500, validation accuracy 0.97960\nModel updated and saved in file: ./cache/model/\nEpoch: 0001, batch_index 1100/5500, training accuracy 0.92000\nEpoch: 0001, batch_index 1200/5500, training accuracy 0.98000\nEpoch: 0001, batch_index 1300/5500, training accuracy 0.98000\nEpoch: 0001, batch_index 1400/5500, training accuracy 0.96000\nEpoch: 0001, batch_index 1500/5500, training accuracy 0.96000\nEpoch: 0001, batch_index 1500/5500, validation accuracy 0.98460\nModel updated and saved in file: ./cache/model/\nEpoch: 0001, batch_index 1600/5500, training accuracy 0.98000\nEpoch: 0001, batch_index 1700/5500, training accuracy 0.96000\nEpoch: 0001, batch_index 1800/5500, training accuracy 0.98000\nEpoch: 0001, batch_index 1900/5500, training accuracy 0.94000\nEpoch: 0001, batch_index 2000/5500, training accuracy 0.94000\nEpoch: 0001, batch_index 2000/5500, validation accuracy 0.98380\nEpoch: 0001, batch_index 2100/5500, training accuracy 0.96000\nEpoch: 0001, batch_index 2200/5500, training accuracy 1.00000\nEpoch: 0001, batch_index 2300/5500, training accuracy 0.98000\nEpoch: 0001, batch_index 2400/5500, training accuracy 1.00000\nEpoch: 0001, batch_index 2500/5500, training accuracy 1.00000\nEpoch: 0001, batch_index 2500/5500, validation accuracy 0.98900\nModel updated and saved in file: ./cache/model/\nEpoch: 0001, batch_index 2600/5500, training accuracy 0.94000\nEpoch: 0001, batch_index 2700/5500, training accuracy 1.00000\nEpoch: 0001, batch_index 2800/5500, training accuracy 0.94000\nEpoch: 0001, batch_index 2900/5500, training accuracy 0.96000\nEpoch: 0001, batch_index 3000/5500, training accuracy 0.94000\nEpoch: 0001, batch_index 3000/5500, validation accuracy 0.99080\nModel updated and saved in file: ./cache/model/\nEpoch: 0001, batch_index 3100/5500, training accuracy 0.98000\nEpoch: 0001, batch_index 3200/5500, training accuracy 1.00000\nEpoch: 0001, batch_index 3300/5500, training accuracy 0.90000\nEpoch: 0001, batch_index 3400/5500, training accuracy 0.98000\nEpoch: 0001, batch_index 3500/5500, training accuracy 0.96000\nEpoch: 0001, batch_index 3500/5500, validation accuracy 0.98980\nEpoch: 0001, batch_index 3600/5500, training accuracy 0.98000\nEpoch: 0001, batch_index 3700/5500, training accuracy 0.98000\nEpoch: 0001, batch_index 3800/5500, training accuracy 0.98000\nEpoch: 0001, batch_index 3900/5500, training accuracy 1.00000\nEpoch: 0001, batch_index 4000/5500, training accuracy 1.00000\nEpoch: 0001, batch_index 4000/5500, validation accuracy 0.99040\nEpoch: 0001, batch_index 4100/5500, training accuracy 0.96000\nEpoch: 0001, batch_index 4200/5500, training accuracy 1.00000\nEpoch: 0001, batch_index 4300/5500, training accuracy 1.00000\nEpoch: 0001, batch_index 4400/5500, training accuracy 1.00000\nEpoch: 0001, batch_index 4500/5500, training accuracy 1.00000\nEpoch: 0001, batch_index 4500/5500, validation accuracy 0.99000\nEpoch: 0001, batch_index 4600/5500, training accuracy 1.00000\nEpoch: 0001, batch_index 4700/5500, training accuracy 1.00000\nEpoch: 0001, batch_index 4800/5500, training accuracy 0.96000\nEpoch: 0001, batch_index 4900/5500, training accuracy 1.00000\nEpoch: 0001, batch_index 5000/5500, training accuracy 0.96000\nEpoch: 0001, batch_index 5000/5500, validation accuracy 0.99020\nEpoch: 0001, batch_index 5100/5500, training accuracy 1.00000\nEpoch: 0001, batch_index 5200/5500, training accuracy 1.00000\nEpoch: 0001, batch_index 5300/5500, training accuracy 0.96000\nEpoch: 0001, batch_index 5400/5500, training accuracy 1.00000\nEpoch: 0002, batch_index    0/5500, training accuracy 0.98000\nEpoch: 0002, batch_index    0/5500, validation accuracy 0.98880\nEpoch: 0002, batch_index  100/5500, training accuracy 0.96000\nEpoch: 0002, batch_index  200/5500, training accuracy 1.00000\nEpoch: 0002, batch_index  300/5500, training accuracy 1.00000\nEpoch: 0002, batch_index  400/5500, training accuracy 0.96000\nEpoch: 0002, batch_index  500/5500, training accuracy 1.00000\nEpoch: 0002, batch_index  500/5500, validation accuracy 0.99100\nModel updated and saved in file: ./cache/model/\nEpoch: 0002, batch_index  600/5500, training accuracy 0.98000\nEpoch: 0002, batch_index  700/5500, training accuracy 0.98000\nEpoch: 0002, batch_index  800/5500, training accuracy 0.98000\nEpoch: 0002, batch_index  900/5500, training accuracy 0.98000\nEpoch: 0002, batch_index 1000/5500, training accuracy 0.94000\nEpoch: 0002, batch_index 1000/5500, validation accuracy 0.99060\nEpoch: 0002, batch_index 1100/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 1200/5500, training accuracy 0.98000\nEpoch: 0002, batch_index 1300/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 1400/5500, training accuracy 0.98000\nEpoch: 0002, batch_index 1500/5500, training accuracy 0.98000\nEpoch: 0002, batch_index 1500/5500, validation accuracy 0.99080\nEpoch: 0002, batch_index 1600/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 1700/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 1800/5500, training accuracy 0.98000\nEpoch: 0002, batch_index 1900/5500, training accuracy 0.98000\nEpoch: 0002, batch_index 2000/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 2000/5500, validation accuracy 0.99080\nEpoch: 0002, batch_index 2100/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 2200/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 2300/5500, training accuracy 0.98000\nEpoch: 0002, batch_index 2400/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 2500/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 2500/5500, validation accuracy 0.99140\nModel updated and saved in file: ./cache/model/\nEpoch: 0002, batch_index 2600/5500, training accuracy 0.98000\nEpoch: 0002, batch_index 2700/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 2800/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 2900/5500, training accuracy 0.98000\nEpoch: 0002, batch_index 3000/5500, training accuracy 0.98000\nEpoch: 0002, batch_index 3000/5500, validation accuracy 0.99340\nModel updated and saved in file: ./cache/model/\nEpoch: 0002, batch_index 3100/5500, training accuracy 0.98000\nEpoch: 0002, batch_index 3200/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 3300/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 3400/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 3500/5500, training accuracy 0.98000\nEpoch: 0002, batch_index 3500/5500, validation accuracy 0.99180\nEpoch: 0002, batch_index 3600/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 3700/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 3800/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 3900/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 4000/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 4000/5500, validation accuracy 0.99240\nEpoch: 0002, batch_index 4100/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 4200/5500, training accuracy 0.98000\nEpoch: 0002, batch_index 4300/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 4400/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 4500/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 4500/5500, validation accuracy 0.99300\nEpoch: 0002, batch_index 4600/5500, training accuracy 0.96000\nEpoch: 0002, batch_index 4700/5500, training accuracy 0.98000\nEpoch: 0002, batch_index 4800/5500, training accuracy 0.98000\n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 0002, batch_index 4900/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 5000/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 5000/5500, validation accuracy 0.99040\nEpoch: 0002, batch_index 5100/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 5200/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 5300/5500, training accuracy 1.00000\nEpoch: 0002, batch_index 5400/5500, training accuracy 0.98000\nEpoch: 0003, batch_index    0/5500, training accuracy 1.00000\nEpoch: 0003, batch_index    0/5500, validation accuracy 0.99280\nEpoch: 0003, batch_index  100/5500, training accuracy 0.98000\nEpoch: 0003, batch_index  200/5500, training accuracy 0.98000\nEpoch: 0003, batch_index  300/5500, training accuracy 1.00000\nEpoch: 0003, batch_index  400/5500, training accuracy 1.00000\nEpoch: 0003, batch_index  500/5500, training accuracy 0.98000\nEpoch: 0003, batch_index  500/5500, validation accuracy 0.99300\nEpoch: 0003, batch_index  600/5500, training accuracy 1.00000\nEpoch: 0003, batch_index  700/5500, training accuracy 1.00000\nEpoch: 0003, batch_index  800/5500, training accuracy 0.94000\nEpoch: 0003, batch_index  900/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 1000/5500, training accuracy 0.98000\nEpoch: 0003, batch_index 1000/5500, validation accuracy 0.99340\nEpoch: 0003, batch_index 1100/5500, training accuracy 0.98000\nEpoch: 0003, batch_index 1200/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 1300/5500, training accuracy 0.98000\nEpoch: 0003, batch_index 1400/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 1500/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 1500/5500, validation accuracy 0.99240\nEpoch: 0003, batch_index 1600/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 1700/5500, training accuracy 0.98000\nEpoch: 0003, batch_index 1800/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 1900/5500, training accuracy 0.98000\nEpoch: 0003, batch_index 2000/5500, training accuracy 0.98000\nEpoch: 0003, batch_index 2000/5500, validation accuracy 0.99240\nEpoch: 0003, batch_index 2100/5500, training accuracy 0.98000\nEpoch: 0003, batch_index 2200/5500, training accuracy 0.98000\nEpoch: 0003, batch_index 2300/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 2400/5500, training accuracy 0.98000\nEpoch: 0003, batch_index 2500/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 2500/5500, validation accuracy 0.99300\nEpoch: 0003, batch_index 2600/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 2700/5500, training accuracy 0.98000\nEpoch: 0003, batch_index 2800/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 2900/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 3000/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 3000/5500, validation accuracy 0.99280\nEpoch: 0003, batch_index 3100/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 3200/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 3300/5500, training accuracy 0.98000\nEpoch: 0003, batch_index 3400/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 3500/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 3500/5500, validation accuracy 0.99320\nEpoch: 0003, batch_index 3600/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 3700/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 3800/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 3900/5500, training accuracy 0.98000\nEpoch: 0003, batch_index 4000/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 4000/5500, validation accuracy 0.99240\nEpoch: 0003, batch_index 4100/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 4200/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 4300/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 4400/5500, training accuracy 0.98000\nEpoch: 0003, batch_index 4500/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 4500/5500, validation accuracy 0.99280\nEpoch: 0003, batch_index 4600/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 4700/5500, training accuracy 0.98000\nEpoch: 0003, batch_index 4800/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 4900/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 5000/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 5000/5500, validation accuracy 0.99140\nEpoch: 0003, batch_index 5100/5500, training accuracy 0.98000\nEpoch: 0003, batch_index 5200/5500, training accuracy 1.00000\nEpoch: 0003, batch_index 5300/5500, training accuracy 0.98000\nEpoch: 0003, batch_index 5400/5500, training accuracy 1.00000\nEpoch: 0004, batch_index    0/5500, training accuracy 1.00000\nEpoch: 0004, batch_index    0/5500, validation accuracy 0.99520\nModel updated and saved in file: ./cache/model/\nEpoch: 0004, batch_index  100/5500, training accuracy 1.00000\nEpoch: 0004, batch_index  200/5500, training accuracy 1.00000\nEpoch: 0004, batch_index  300/5500, training accuracy 1.00000\nEpoch: 0004, batch_index  400/5500, training accuracy 0.98000\nEpoch: 0004, batch_index  500/5500, training accuracy 1.00000\nEpoch: 0004, batch_index  500/5500, validation accuracy 0.99340\nEpoch: 0004, batch_index  600/5500, training accuracy 1.00000\nEpoch: 0004, batch_index  700/5500, training accuracy 0.98000\nEpoch: 0004, batch_index  800/5500, training accuracy 1.00000\nEpoch: 0004, batch_index  900/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 1000/5500, training accuracy 0.98000\nEpoch: 0004, batch_index 1000/5500, validation accuracy 0.99460\nEpoch: 0004, batch_index 1100/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 1200/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 1300/5500, training accuracy 0.98000\nEpoch: 0004, batch_index 1400/5500, training accuracy 0.98000\nEpoch: 0004, batch_index 1500/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 1500/5500, validation accuracy 0.99320\nEpoch: 0004, batch_index 1600/5500, training accuracy 0.98000\nEpoch: 0004, batch_index 1700/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 1800/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 1900/5500, training accuracy 0.98000\nEpoch: 0004, batch_index 2000/5500, training accuracy 0.98000\nEpoch: 0004, batch_index 2000/5500, validation accuracy 0.99340\nEpoch: 0004, batch_index 2100/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 2200/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 2300/5500, training accuracy 0.98000\nEpoch: 0004, batch_index 2400/5500, training accuracy 0.98000\nEpoch: 0004, batch_index 2500/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 2500/5500, validation accuracy 0.99520\nEpoch: 0004, batch_index 2600/5500, training accuracy 0.96000\nEpoch: 0004, batch_index 2700/5500, training accuracy 0.98000\nEpoch: 0004, batch_index 2800/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 2900/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 3000/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 3000/5500, validation accuracy 0.99380\nEpoch: 0004, batch_index 3100/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 3200/5500, training accuracy 0.98000\nEpoch: 0004, batch_index 3300/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 3400/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 3500/5500, training accuracy 0.98000\nEpoch: 0004, batch_index 3500/5500, validation accuracy 0.99340\nEpoch: 0004, batch_index 3600/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 3700/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 3800/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 3900/5500, training accuracy 0.98000\nEpoch: 0004, batch_index 4000/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 4000/5500, validation accuracy 0.99240\nEpoch: 0004, batch_index 4100/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 4200/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 4300/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 4400/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 4500/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 4500/5500, validation accuracy 0.99440\nEpoch: 0004, batch_index 4600/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 4700/5500, training accuracy 1.00000\n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 0004, batch_index 4800/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 4900/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 5000/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 5000/5500, validation accuracy 0.99380\nEpoch: 0004, batch_index 5100/5500, training accuracy 0.98000\nEpoch: 0004, batch_index 5200/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 5300/5500, training accuracy 1.00000\nEpoch: 0004, batch_index 5400/5500, training accuracy 1.00000\nEpoch: 0005, batch_index    0/5500, training accuracy 1.00000\nEpoch: 0005, batch_index    0/5500, validation accuracy 0.99380\nEpoch: 0005, batch_index  100/5500, training accuracy 0.98000\nEpoch: 0005, batch_index  200/5500, training accuracy 1.00000\nEpoch: 0005, batch_index  300/5500, training accuracy 1.00000\nEpoch: 0005, batch_index  400/5500, training accuracy 1.00000\nEpoch: 0005, batch_index  500/5500, training accuracy 1.00000\nEpoch: 0005, batch_index  500/5500, validation accuracy 0.99300\nEpoch: 0005, batch_index  600/5500, training accuracy 0.98000\nEpoch: 0005, batch_index  700/5500, training accuracy 0.98000\nEpoch: 0005, batch_index  800/5500, training accuracy 1.00000\nEpoch: 0005, batch_index  900/5500, training accuracy 0.98000\nEpoch: 0005, batch_index 1000/5500, training accuracy 0.98000\nEpoch: 0005, batch_index 1000/5500, validation accuracy 0.99340\nEpoch: 0005, batch_index 1100/5500, training accuracy 0.98000\nEpoch: 0005, batch_index 1200/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 1300/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 1400/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 1500/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 1500/5500, validation accuracy 0.99340\nEpoch: 0005, batch_index 1600/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 1700/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 1800/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 1900/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 2000/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 2000/5500, validation accuracy 0.99480\nEpoch: 0005, batch_index 2100/5500, training accuracy 0.98000\nEpoch: 0005, batch_index 2200/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 2300/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 2400/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 2500/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 2500/5500, validation accuracy 0.99400\nEpoch: 0005, batch_index 2600/5500, training accuracy 0.98000\nEpoch: 0005, batch_index 2700/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 2800/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 2900/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 3000/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 3000/5500, validation accuracy 0.99500\nEpoch: 0005, batch_index 3100/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 3200/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 3300/5500, training accuracy 0.98000\nEpoch: 0005, batch_index 3400/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 3500/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 3500/5500, validation accuracy 0.99280\nEpoch: 0005, batch_index 3600/5500, training accuracy 0.98000\nEpoch: 0005, batch_index 3700/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 3800/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 3900/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 4000/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 4000/5500, validation accuracy 0.99400\nEpoch: 0005, batch_index 4100/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 4200/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 4300/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 4400/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 4500/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 4500/5500, validation accuracy 0.99460\nEpoch: 0005, batch_index 4600/5500, training accuracy 0.98000\nEpoch: 0005, batch_index 4700/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 4800/5500, training accuracy 0.98000\nEpoch: 0005, batch_index 4900/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 5000/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 5000/5500, validation accuracy 0.99460\nEpoch: 0005, batch_index 5100/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 5200/5500, training accuracy 0.98000\nEpoch: 0005, batch_index 5300/5500, training accuracy 1.00000\nEpoch: 0005, batch_index 5400/5500, training accuracy 1.00000\nEpoch: 0006, batch_index    0/5500, training accuracy 1.00000\nEpoch: 0006, batch_index    0/5500, validation accuracy 0.99480\nEpoch: 0006, batch_index  100/5500, training accuracy 1.00000\nEpoch: 0006, batch_index  200/5500, training accuracy 1.00000\nEpoch: 0006, batch_index  300/5500, training accuracy 1.00000\nEpoch: 0006, batch_index  400/5500, training accuracy 1.00000\nEpoch: 0006, batch_index  500/5500, training accuracy 1.00000\nEpoch: 0006, batch_index  500/5500, validation accuracy 0.99340\nEpoch: 0006, batch_index  600/5500, training accuracy 1.00000\nEpoch: 0006, batch_index  700/5500, training accuracy 1.00000\nEpoch: 0006, batch_index  800/5500, training accuracy 0.98000\nEpoch: 0006, batch_index  900/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 1000/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 1000/5500, validation accuracy 0.99440\nEpoch: 0006, batch_index 1100/5500, training accuracy 0.98000\nEpoch: 0006, batch_index 1200/5500, training accuracy 0.98000\nEpoch: 0006, batch_index 1300/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 1400/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 1500/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 1500/5500, validation accuracy 0.99320\nEpoch: 0006, batch_index 1600/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 1700/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 1800/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 1900/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 2000/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 2000/5500, validation accuracy 0.99500\nEpoch: 0006, batch_index 2100/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 2200/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 2300/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 2400/5500, training accuracy 0.98000\nEpoch: 0006, batch_index 2500/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 2500/5500, validation accuracy 0.99400\nEpoch: 0006, batch_index 2600/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 2700/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 2800/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 2900/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 3000/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 3000/5500, validation accuracy 0.99400\nEpoch: 0006, batch_index 3100/5500, training accuracy 0.98000\nEpoch: 0006, batch_index 3200/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 3300/5500, training accuracy 0.98000\nEpoch: 0006, batch_index 3400/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 3500/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 3500/5500, validation accuracy 0.99500\nEpoch: 0006, batch_index 3600/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 3700/5500, training accuracy 0.98000\nEpoch: 0006, batch_index 3800/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 3900/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 4000/5500, training accuracy 0.98000\nEpoch: 0006, batch_index 4000/5500, validation accuracy 0.99460\nEpoch: 0006, batch_index 4100/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 4200/5500, training accuracy 0.98000\nEpoch: 0006, batch_index 4300/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 4400/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 4500/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 4500/5500, validation accuracy 0.99480\nEpoch: 0006, batch_index 4600/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 4700/5500, training accuracy 1.00000\n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 0006, batch_index 4800/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 4900/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 5000/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 5000/5500, validation accuracy 0.99460\nEpoch: 0006, batch_index 5100/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 5200/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 5300/5500, training accuracy 1.00000\nEpoch: 0006, batch_index 5400/5500, training accuracy 1.00000\nEpoch: 0007, batch_index    0/5500, training accuracy 1.00000\nEpoch: 0007, batch_index    0/5500, validation accuracy 0.99400\nEpoch: 0007, batch_index  100/5500, training accuracy 1.00000\nEpoch: 0007, batch_index  200/5500, training accuracy 1.00000\nEpoch: 0007, batch_index  300/5500, training accuracy 1.00000\nEpoch: 0007, batch_index  400/5500, training accuracy 1.00000\nEpoch: 0007, batch_index  500/5500, training accuracy 1.00000\nEpoch: 0007, batch_index  500/5500, validation accuracy 0.99480\nEpoch: 0007, batch_index  600/5500, training accuracy 1.00000\nEpoch: 0007, batch_index  700/5500, training accuracy 1.00000\nEpoch: 0007, batch_index  800/5500, training accuracy 1.00000\nEpoch: 0007, batch_index  900/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 1000/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 1000/5500, validation accuracy 0.99460\nEpoch: 0007, batch_index 1100/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 1200/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 1300/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 1400/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 1500/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 1500/5500, validation accuracy 0.99440\nEpoch: 0007, batch_index 1600/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 1700/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 1800/5500, training accuracy 0.98000\nEpoch: 0007, batch_index 1900/5500, training accuracy 0.98000\nEpoch: 0007, batch_index 2000/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 2000/5500, validation accuracy 0.99500\nEpoch: 0007, batch_index 2100/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 2200/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 2300/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 2400/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 2500/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 2500/5500, validation accuracy 0.99460\nEpoch: 0007, batch_index 2600/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 2700/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 2800/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 2900/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 3000/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 3000/5500, validation accuracy 0.99460\nEpoch: 0007, batch_index 3100/5500, training accuracy 0.98000\nEpoch: 0007, batch_index 3200/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 3300/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 3400/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 3500/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 3500/5500, validation accuracy 0.99380\nEpoch: 0007, batch_index 3600/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 3700/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 3800/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 3900/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 4000/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 4000/5500, validation accuracy 0.99460\nEpoch: 0007, batch_index 4100/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 4200/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 4300/5500, training accuracy 0.98000\nEpoch: 0007, batch_index 4400/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 4500/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 4500/5500, validation accuracy 0.99400\nEpoch: 0007, batch_index 4600/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 4700/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 4800/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 4900/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 5000/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 5000/5500, validation accuracy 0.99360\nEpoch: 0007, batch_index 5100/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 5200/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 5300/5500, training accuracy 1.00000\nEpoch: 0007, batch_index 5400/5500, training accuracy 1.00000\nEpoch: 0008, batch_index    0/5500, training accuracy 1.00000\nEpoch: 0008, batch_index    0/5500, validation accuracy 0.99460\nEpoch: 0008, batch_index  100/5500, training accuracy 1.00000\nEpoch: 0008, batch_index  200/5500, training accuracy 1.00000\nEpoch: 0008, batch_index  300/5500, training accuracy 1.00000\nEpoch: 0008, batch_index  400/5500, training accuracy 1.00000\nEpoch: 0008, batch_index  500/5500, training accuracy 1.00000\nEpoch: 0008, batch_index  500/5500, validation accuracy 0.99360\nEpoch: 0008, batch_index  600/5500, training accuracy 1.00000\nEpoch: 0008, batch_index  700/5500, training accuracy 1.00000\nEpoch: 0008, batch_index  800/5500, training accuracy 1.00000\nEpoch: 0008, batch_index  900/5500, training accuracy 0.98000\nEpoch: 0008, batch_index 1000/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 1000/5500, validation accuracy 0.99380\nEpoch: 0008, batch_index 1100/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 1200/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 1300/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 1400/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 1500/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 1500/5500, validation accuracy 0.99420\nEpoch: 0008, batch_index 1600/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 1700/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 1800/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 1900/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 2000/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 2000/5500, validation accuracy 0.99400\nEpoch: 0008, batch_index 2100/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 2200/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 2300/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 2400/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 2500/5500, training accuracy 0.98000\nEpoch: 0008, batch_index 2500/5500, validation accuracy 0.99520\nEpoch: 0008, batch_index 2600/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 2700/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 2800/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 2900/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 3000/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 3000/5500, validation accuracy 0.99380\nEpoch: 0008, batch_index 3100/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 3200/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 3300/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 3400/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 3500/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 3500/5500, validation accuracy 0.99520\nEpoch: 0008, batch_index 3600/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 3700/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 3800/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 3900/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 4000/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 4000/5500, validation accuracy 0.99440\nEpoch: 0008, batch_index 4100/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 4200/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 4300/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 4400/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 4500/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 4500/5500, validation accuracy 0.99440\nEpoch: 0008, batch_index 4600/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 4700/5500, training accuracy 1.00000\n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 0008, batch_index 4800/5500, training accuracy 0.98000\nEpoch: 0008, batch_index 4900/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 5000/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 5000/5500, validation accuracy 0.99480\nEpoch: 0008, batch_index 5100/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 5200/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 5300/5500, training accuracy 1.00000\nEpoch: 0008, batch_index 5400/5500, training accuracy 0.98000\nEpoch: 0009, batch_index    0/5500, training accuracy 1.00000\nEpoch: 0009, batch_index    0/5500, validation accuracy 0.99460\nEpoch: 0009, batch_index  100/5500, training accuracy 1.00000\nEpoch: 0009, batch_index  200/5500, training accuracy 1.00000\nEpoch: 0009, batch_index  300/5500, training accuracy 1.00000\nEpoch: 0009, batch_index  400/5500, training accuracy 1.00000\nEpoch: 0009, batch_index  500/5500, training accuracy 1.00000\nEpoch: 0009, batch_index  500/5500, validation accuracy 0.99480\nEpoch: 0009, batch_index  600/5500, training accuracy 1.00000\nEpoch: 0009, batch_index  700/5500, training accuracy 1.00000\nEpoch: 0009, batch_index  800/5500, training accuracy 1.00000\nEpoch: 0009, batch_index  900/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 1000/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 1000/5500, validation accuracy 0.99320\nEpoch: 0009, batch_index 1100/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 1200/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 1300/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 1400/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 1500/5500, training accuracy 0.98000\nEpoch: 0009, batch_index 1500/5500, validation accuracy 0.99400\nEpoch: 0009, batch_index 1600/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 1700/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 1800/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 1900/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 2000/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 2000/5500, validation accuracy 0.99460\nEpoch: 0009, batch_index 2100/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 2200/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 2300/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 2400/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 2500/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 2500/5500, validation accuracy 0.99500\nEpoch: 0009, batch_index 2600/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 2700/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 2800/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 2900/5500, training accuracy 0.98000\nEpoch: 0009, batch_index 3000/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 3000/5500, validation accuracy 0.99480\nEpoch: 0009, batch_index 3100/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 3200/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 3300/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 3400/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 3500/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 3500/5500, validation accuracy 0.99440\nEpoch: 0009, batch_index 3600/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 3700/5500, training accuracy 0.98000\nEpoch: 0009, batch_index 3800/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 3900/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 4000/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 4000/5500, validation accuracy 0.99400\nEpoch: 0009, batch_index 4100/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 4200/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 4300/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 4400/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 4500/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 4500/5500, validation accuracy 0.99340\nEpoch: 0009, batch_index 4600/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 4700/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 4800/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 4900/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 5000/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 5000/5500, validation accuracy 0.99540\nModel updated and saved in file: ./cache/model/\nEpoch: 0009, batch_index 5100/5500, training accuracy 0.98000\nEpoch: 0009, batch_index 5200/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 5300/5500, training accuracy 1.00000\nEpoch: 0009, batch_index 5400/5500, training accuracy 1.00000\nEpoch: 0010, batch_index    0/5500, training accuracy 1.00000\nEpoch: 0010, batch_index    0/5500, validation accuracy 0.99560\nModel updated and saved in file: ./cache/model/\nEpoch: 0010, batch_index  100/5500, training accuracy 1.00000\nEpoch: 0010, batch_index  200/5500, training accuracy 1.00000\nEpoch: 0010, batch_index  300/5500, training accuracy 1.00000\nEpoch: 0010, batch_index  400/5500, training accuracy 1.00000\nEpoch: 0010, batch_index  500/5500, training accuracy 1.00000\nEpoch: 0010, batch_index  500/5500, validation accuracy 0.99640\nModel updated and saved in file: ./cache/model/\nEpoch: 0010, batch_index  600/5500, training accuracy 1.00000\nEpoch: 0010, batch_index  700/5500, training accuracy 1.00000\nEpoch: 0010, batch_index  800/5500, training accuracy 1.00000\nEpoch: 0010, batch_index  900/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 1000/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 1000/5500, validation accuracy 0.99560\nEpoch: 0010, batch_index 1100/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 1200/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 1300/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 1400/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 1500/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 1500/5500, validation accuracy 0.99480\nEpoch: 0010, batch_index 1600/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 1700/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 1800/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 1900/5500, training accuracy 0.98000\nEpoch: 0010, batch_index 2000/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 2000/5500, validation accuracy 0.99520\nEpoch: 0010, batch_index 2100/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 2200/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 2300/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 2400/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 2500/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 2500/5500, validation accuracy 0.99560\nEpoch: 0010, batch_index 2600/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 2700/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 2800/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 2900/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 3000/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 3000/5500, validation accuracy 0.99600\nEpoch: 0010, batch_index 3100/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 3200/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 3300/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 3400/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 3500/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 3500/5500, validation accuracy 0.99400\nEpoch: 0010, batch_index 3600/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 3700/5500, training accuracy 0.98000\nEpoch: 0010, batch_index 3800/5500, training accuracy 0.98000\nEpoch: 0010, batch_index 3900/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 4000/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 4000/5500, validation accuracy 0.99360\nEpoch: 0010, batch_index 4100/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 4200/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 4300/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 4400/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 4500/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 4500/5500, validation accuracy 0.99500\n", "name": "stdout"}, {"output_type": "stream", "text": "Epoch: 0010, batch_index 4600/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 4700/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 4800/5500, training accuracy 0.98000\nEpoch: 0010, batch_index 4900/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 5000/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 5000/5500, validation accuracy 0.99380\nEpoch: 0010, batch_index 5100/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 5200/5500, training accuracy 0.98000\nEpoch: 0010, batch_index 5300/5500, training accuracy 1.00000\nEpoch: 0010, batch_index 5400/5500, training accuracy 1.00000\n", "name": "stdout"}, {"output_type": "stream", "text": "INFO:tensorflow:Restoring parameters from ./cache/model/\n", "name": "stderr"}, {"output_type": "stream", "text": "Optimization Finished!\ntest accuracy for the stored model: 0.9948\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "\u4ee5\u4e0b\u90e8\u5206\u5c1a\u672a\u66f4\u6539"}, {"metadata": {}, "cell_type": "markdown", "source": "## <a name=\"predict\">2. \u9884\u6d4b</a>  \n\n"}, {"metadata": {}, "cell_type": "markdown", "source": "&#8195;&#8195; \u5728\u4e0a\u9762\u8bad\u7ec3\u7684\u57fa\u7840\u4e0a\uff0c\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u7528\u8bad\u7ec3\u7684\u6a21\u578b\u8fdb\u884c\u9884\u6d4b\u4f5c\u4e1a\u3002\u5982\u8bfb\u53d6OBS\u6876\u4e2d\u7684\u6570\u5b57\u56fe\u7247\u8fdb\u884c\u8bc6\u522b\u3002input_fn \u5bf9\u8f93\u5165\u56fe\u7247\u8fdb\u884c\u7b80\u5355\u5904\u7406\uff0c\u5f97\u5230\u7f51\u7edc\u5141\u8bb8\u7684\u8f93\u5165tensor\uff1bmodel_fn\u5b9a\u4e49\u4e00\u4e2a\u9884\u6d4b\u5185\u5bb9\uff0c\u540c\u65f6\uff0c\u8fd8\u9700\u5b9a\u4e49\u4e00\u4e2a\u5bf9\u8f93\u51fa\u5904\u7406\u7684\u51fd\u6570output_fn\uff0c\u6211\u4eec\u5728\u6539\u51fd\u6570\u91cc\u5bf9\u8f93\u51fa\u8fdb\u884c\u4e00\u4e2a\u6253\u5370\u8f93\u51fa\u3002\n \n  \u8fd8\u9700\u5728 mox.run()\u51fd\u6570\u4e2d\u52a0\u5165\u5982\u4e0b\u53c2\u6570\uff1a\n  \n &#8195;&#8195; \u8f93\u51fa\u51fd\u6570 output_fn: A callback with args of results from sess.run.\n   \n&#8195;&#8195; \u6a21\u578b\u52a0\u8f7d\u4f4d\u7f6e checkpoint_path: Directory or file path of ckpt to restore when `run_mode` is 'evaluation'.\n                          Useless when `run_mode` is 'train'."}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "####### your coding place\uff1a begin###########\n\n#\u6b64\u5904\u5fc5\u987b\u4fee\u6539\u4e3a\u7528\u6237\u6570\u636e\u5b58\u50a8\u7684OBS\u4f4d\u7f6e\n\n# \u9884\u6d4b\u56fe\u7247\u5728OBS\u7684\u5b58\u50a8\u4f4d\u7f6e\u3002\n# eg. \u56fe\u7247\u540d\u79f0\uff1a  image_number.jpg\n#     \u5b58\u50a8\u4f4d\u7f6e\u4e3a\uff1abucket/test/\nsrc_path = 's3://bucket/test/image_number.jpg'\n\n####### your coding place\uff1a end  ###########", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "# \u53ef\u4ee5\u5229\u7528moxing \u5c06\u9700\u8981\u9884\u6d4b\u7684\u56fe\u7247\u4eceOBS\u62f7\u8d1d\u5230\u672c\u5730\nif not mox.file.exists(src_path):\n    raise ValueError('Plese verify your src_path!')\ndst_path =  './cache/test.jpg'\nmox.file.copy(src_path,dst_path)", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "image_path = './cache/test.jpg'            # \u6307\u5b9a\u56fe\u7247\u4f4d\u7f6e\ncheckpoint_url = './cache/log/'         # \u6307\u5b9acheckpoint\u4f4d\u7f6e\uff0c\u5373\u4e0a\u4e00\u6b65\u8bad\u7ec3\u6307\u5b9a\u7684\u8def\u5f84\u7684\u4f4d\u7f6e\u3002\nprint(mox.file.exists(image_path))", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "import moxing.tensorflow as mox\nimport os\nimport tensorflow as tf\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n", "execution_count": null, "outputs": []}, {"metadata": {"trusted": false}, "cell_type": "code", "source": "def predict(*args):\n  def input_fn(run_mode, **kwargs):\n    image = tf.read_file(image_path)\n    img = tf.image.decode_jpeg(image, channels=1)\n    img = tf.image.resize_images(img, [28, 28], 0)\n    img = tf.reshape(img, [784])\n    return img\n\n  def model_fn(inputs, run_mode, **kwargs):\n    x = inputs\n    W1 = tf.get_variable(name='W', initializer=tf.zeros([784, 10]))\n    b1 = tf.get_variable(name='b', initializer=tf.zeros([10]))\n    y = tf.matmul(x, W1) + b1\n    predictions = tf.argmax(y, 1)\n    return mox.ModelSpec(output_info={'predict': predictions})\n\n  def output_fn(outputs):\n    for output in outputs:\n      result = output['predict']\n      print(\"The result\uff1a\",result)\n\n  mox.run(input_fn=input_fn,\n          model_fn=model_fn,\n          output_fn=output_fn,\n          run_mode=mox.ModeKeys.PREDICT,\n          batch_size=1,\n          auto_batch=False,\n          max_number_of_steps=1,\n          output_every_n_steps=1,\n          checkpoint_path=checkpoint_url)\nif __name__ == '__main__':\n  tf.app.run(main=predict)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "\u901a\u8fc7\u9884\u6d4b\uff0c\u6211\u4eec\u80fd\u591f\u770b\u5230\u7ed3\u679c\u8f93\u51fa\u3002\n"}], "metadata": {"kernelspec": {"name": "tensorflow-1.8", "display_name": "TensorFlow-1.8", "language": "python"}, "language_info": {"name": "python", "version": "3.6.4", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}