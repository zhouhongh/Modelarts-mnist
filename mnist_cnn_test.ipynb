{"cells": [{"metadata": {"trusted": true}, "cell_type": "code", "source": "# Some code was borrowed from https://github.com/petewarden/tensorflow_makefile/blob/master/tensorflow/models/image/mnist/convolutional.py\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy\nimport os\nimport tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\n\nimport mnist_data\nimport cnn_model\n\n# user input\nfrom argparse import ArgumentParser\n\ntf.reset_default_graph()\n# refernce argument values\nMODEL_DIRECTORY = \"./cache/model/\"\nTEST_BATCH_SIZE = 5000\nENSEMBLE = False\n\n# # build parser\n# def build_parser():\n#     parser = ArgumentParser()\n\n#     parser.add_argument('--model-dir', default='./cache/model/' ,\n#                         dest='model_directory', help='directory where model to be tested is stored',\n#                         metavar='MODEL_DIRECTORY', required=False)\n#     parser.add_argument('--batch-size', type=int, default=5000,\n#                         dest='batch_size', help='batch size for test',\n#                         metavar='TEST_BATCH_SIZE', required=False)\n#     parser.add_argument('--use-ensemble', default= False, \n#                         dest='ensemble', help='boolean for usage of ensemble',\n#                         metavar='ENSEMBLE', required=False)\n#     return parser\n\n# test with test data given by mnist_data.py\ndef test(model_directory, batch_size):\n    # Import data\n    PIXEL_DEPTH = mnist_data.PIXEL_DEPTH\n    mnist = input_data.read_data_sets('./cache/local_data/', one_hot=True)\n\n    is_training = tf.placeholder(tf.bool, name='MODE')\n\n    # tf Graph input\n    x = tf.placeholder(tf.float32, [None, 784])\n    y_ = tf.placeholder(tf.float32, [None, 10])  # answer\n    y = cnn_model.CNN(x, is_training=is_training)\n\n    # Add ops to save and restore all the variables\n    sess = tf.InteractiveSession()\n    sess.run(tf.global_variables_initializer(), feed_dict={is_training: True})\n\n    # Restore variables from disk\n    saver = tf.train.Saver()\n\n    # Calculate accuracy for all mnist test images\n    test_size = mnist.test.num_examples\n    total_batch = int(test_size / batch_size)\n\n    saver.restore(sess, model_directory)\n\n    acc_buffer = []\n    # Loop over all batches\n    for i in range(total_batch):\n\n        batch = mnist.test.next_batch(batch_size)\n        batch_xs = (batch[0] - (PIXEL_DEPTH / 2.0) / PIXEL_DEPTH)  # make zero-centered distribution as in mnist_data.extract_data()\n        batch_ys = batch[1]\n\n        y_final = sess.run(y, feed_dict={x: batch_xs, y_: batch_ys, is_training: False})\n\n        correct_prediction = numpy.equal(numpy.argmax(y_final, 1), numpy.argmax(batch_ys, 1))\n\n        acc_buffer.append(numpy.sum(correct_prediction) / batch_size)\n\n    print(\"test accuracy for the stored model: %g\" % numpy.mean(acc_buffer))\n\n# test with test data given by mnist_data.py\ndef test_org(model_directory, batch_size):\n    # Import data\n    PIXEL_DEPTH = mnist_data.PIXEL_DEPTH\n    train_total_data, train_size, validation_data, validation_labels, test_data, test_labels = mnist_data.prepare_MNIST_data(\n        False)\n\n    is_training = tf.placeholder(tf.bool, name='MODE')\n\n    # tf Graph input\n    x = tf.placeholder(tf.float32, [None, 784])\n    y_ = tf.placeholder(tf.float32, [None, 10])  # answer\n    y = cnn_model.CNN(x, is_training=is_training)\n\n    # Add ops to save and restore all the variables\n    sess = tf.InteractiveSession()\n    sess.run(tf.global_variables_initializer(), feed_dict={is_training: True})\n\n    # Restore variables from disk\n    saver = tf.train.Saver()\n\n    # Calculate accuracy for all mnist test images\n    test_size = test_labels.shape[0]\n    total_batch = int(test_size / batch_size)\n\n    saver.restore(sess, model_directory)\n\n    acc_buffer = []\n\n    # Loop over all batches\n    for i in range(total_batch):\n        # Compute the offset of the current minibatch in the data.\n        offset = (i * batch_size) % (test_size)\n        batch_xs = test_data[offset:(offset + batch_size), :]\n        batch_ys = test_labels[offset:(offset + batch_size), :]\n\n        y_final = sess.run(y, feed_dict={x: batch_xs, y_: batch_ys, is_training: False})\n\n        correct_prediction = numpy.equal(numpy.argmax(y_final, 1), numpy.argmax(batch_ys, 1))\n\n        acc_buffer.append(numpy.sum(correct_prediction) / batch_size)\n\n    print(\"test accuracy for the stored model: %g\" % numpy.mean(acc_buffer))\n\n# For a given matrix, each row is converted into a one-hot row vector\ndef one_hot_matrix(a):\n    a_ = numpy.zeros_like(a)\n    for i, j in zip(numpy.arange(a.shape[0]), numpy.argmax(a, 1)): a_[i, j] = 1\n    return a_\n\n# test with test data given by mnist_data.py\ndef test_ensemble(model_directory_list, batch_size):\n    # Import data\n    PIXEL_DEPTH = mnist_data.PIXEL_DEPTH\n    mnist = input_data.read_data_sets('./cache/local_data/', one_hot=True)\n\n    is_training = tf.placeholder(tf.bool, name='MODE')\n\n    # tf Graph input\n    x = tf.placeholder(tf.float32, [None, 784])\n    y_ = tf.placeholder(tf.float32, [None, 10])  # answer\n    y = cnn_model.CNN(x, is_training=is_training)\n\n    # Add ops to save and restore all the variables\n    sess = tf.InteractiveSession()\n    sess.run(tf.global_variables_initializer(), feed_dict={is_training: True})\n\n    # Restore variables from disk\n    saver = tf.train.Saver()\n\n    # Calculate accuracy for all mnist test images\n    test_size = mnist.test.num_examples\n    total_batch = int(test_size / batch_size)\n\n    acc_buffer = []\n    # Loop over all batches\n    for i in range(total_batch):\n\n        batch = mnist.test.next_batch(batch_size)\n        batch_xs = (batch[0] - (PIXEL_DEPTH / 2.0) / PIXEL_DEPTH)  # make zero-centered distribution as in mnist_data.extract_data()\n        batch_ys = batch[1]\n\n        y_final = numpy.zeros_like(batch_ys)\n\n        for dir in model_directory_list:\n            saver.restore(sess, dir+'/model.ckpt')\n            pred = sess.run(y, feed_dict={x: batch_xs, y_: batch_ys, is_training: False})\n            y_final += one_hot_matrix(pred) # take a majority vote as an answer\n\n        correct_prediction = numpy.equal(numpy.argmax(y_final, 1), numpy.argmax(batch_ys, 1))\n\n        acc_buffer.append(numpy.sum(correct_prediction) / batch_size)\n\n    print(\"test accuracy for the stored model: %g\" % numpy.mean(acc_buffer))\n\nif __name__ == '__main__':\n    # Parse argument\n#     parser = build_parser()\n#     options = parser.parse_args()\n\n    ensemble = ENSEMBLE\n    model_directory = MODEL_DIRECTORY\n    batch_size = TEST_BATCH_SIZE\n    print(\"start:\")\n    # Select ensemble test or a single model test\n    if ensemble=='True': # use ensemble model\n        model_directory_list = [x[0] for x in os.walk(model_directory)]\n        test_ensemble(model_directory_list[1:], batch_size)\n    else: # test a single model\n        # test_org(model_directory, batch_size) #test with test data given by mnist_data.py\n        test(model_directory+'model.ckpt',\n             batch_size)  # test with test data given by tensorflow.examples.tutorials.mnist.input_data()\n\n", "execution_count": 12, "outputs": [{"output_type": "stream", "text": "start:\nExtracting ./cache/local_data/train-images-idx3-ubyte.gz\nExtracting ./cache/local_data/train-labels-idx1-ubyte.gz\nExtracting ./cache/local_data/t10k-images-idx3-ubyte.gz\nExtracting ./cache/local_data/t10k-labels-idx1-ubyte.gz\n", "name": "stdout"}, {"output_type": "stream", "text": "/home/ma-user/anaconda3/envs/TensorFlow-1.8/lib/python3.6/site-packages/tensorflow/python/client/session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n  warnings.warn('An interactive session is already active. This can '\nINFO:tensorflow:Restoring parameters from ./cache/model/model.ckpt\n", "name": "stderr"}, {"output_type": "stream", "text": "test accuracy for the stored model: 0.9953\n", "name": "stdout"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "tensorflow-1.8", "display_name": "TensorFlow-1.8", "language": "python"}, "language_info": {"name": "python", "version": "3.6.4", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 2}